{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kisa Bir Ozet\n",
    "\n",
    "- Yerel doayalar\n",
    "    * [CSV](https://en.wikipedia.org/wiki/Comma-separated_values), [Excel](https://en.wikipedia.org/wiki/Office_Open_XML), [**arrow**](https://arrow.apache.org/), [**parquet**](https://parquet.apache.org/)\n",
    "- Veri Tabani\n",
    "    * [SQL](https://en.wikipedia.org/wiki/SQL), [DuckDB](https://duckdb.org/), [pymongo](https://pypi.org/project/pymongo/), [rdbms](https://pypi.org/project/rdbms/)\n",
    "- Agac Yapida Veriler\n",
    "    * [json](https://docs.python.org/3/library/json.html), [xmltodict](https://pypi.org/project/xmltodict/), [HDF](https://www.h5py.org/)\n",
    "-    API'ler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Veri Temizlemeye Hizli bir Giris\n",
    "\n",
    "Veri keşfi, verinin doğasını anlamak, potansiyel düzensizlikleri tespit etmek ve sonraki analitik süreçlere hazırlık amacıyla ayrıntılı bir analiz yapmayı içerir. Diğer yandan, veri temizleme, çeşitli veri anormalliklerini düzeltmeyi içerir; bu, eksik değerleri ele alma, gereksiz verileri kaldırma ve verinin birliğini sağlama gibi adımları içerir.\n",
    "\n",
    "### Veri İnceleme\n",
    "\n",
    "Veri inceleme konusundaki yetenek, veri setinin yapısını anlamak için temel bir kavrayışa sahip olmak için esastır. Bu yetenek, `head()`, `tail()`, `info()`, `describe()` ve `shape` öznitelikleri gibi temel yöntemleri kullanarak elde edilir. Bu yöntemler, veri kümesi hakkında kritik bilgiler sağlar, bunlar arasında ilk ve son veri kayıtları, veri tipi bilgisi, özet istatistikler ve veri setinin boyutları bulunur.\n",
    "\n",
    "Verileri incelemek için daha önceden [pandas-profiling](https://pypi.org/project/pandas-profiling/) olunan bilinen [ydata-profiling](https://pypi.org/project/ydata-profiling/) isminde şahane bir paket mevcut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Veri Türü Dönüşümü\n",
    "\n",
    "Veri türü dönüşümü hakkında temel bir anlayış, veri tiplerini analitik görevlerin belirli gereksinimleriyle uyumlu hale getirmek için gereklidir. Bu, `astype()` yöntemini ustaca kullanmayı içerir, böylece veri temsil doğruluğunu artırır ve bellek kaynaklarını optimize eder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Eksik ve Tekrarlanan Veri İşleme\n",
    "\n",
    "Bir veri setindeki eksik verilerle başa çıkmanın önemini anlamak önemlidir. Bu, `isna()` ve `isnull()` gibi yöntemler kullanılarak gerçekleştirilen eksik veri örneklerini tanıma tekniklerini ustalaşmayı gerektirir. Ayrıca, eksik verilerle etkili bir şekilde başa çıkmak, `dropna()`, `fillna()` veya eksik değerleri doldurmak için tasarlanmış yöntemlerin ustaca uygulanmasını içerir.\n",
    "\n",
    "Eksik verilerin yanı sıra, tekrarlanan veri girişlerini tanımlamak ve ardından bunları kaldırmak da önemlidir. Bu amaçla, `duplicated()` ve `drop_duplicates()` gibi teknikler vazgeçilmezdir. Çift gözlemlerin ortadan kaldırılması kritiktir, çünkü bunların varlığı analitik prosedürlerin sonuçlarını bozabilir ve veri odaklı sonuçların doğruluğunu tehlikeye atabilir.\n",
    "\n",
    "Ayrıca, alan bazlı elde edilen verilerde bazen NA ve NULL şeklinde olmayabilir. Örneğin, sensör verilerinin kayıt edildiği bir makinede sinyalin zayıf olduğunda 9999 gibi kod atayabilir. Bu gibi durumlarda da eksik veri olarak değerlenirilmelidir. Bu amac icin `replace()` gibi teknikler kullanilabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Veri Üzerinde Yapılan İşlemler\n",
    "\n",
    "Veri analizinde, karmaşıklığı veya boyutu ne olursa olsun herhangi bir veri koleksiyonuna uygulanabilen dört temel kategoriye ait işlemleri bulunmaktadır. Bu temel veri işlemlerini gerçekleştirmek için iki temel yaklaşımı kullanabiliriz: Python'da veri manipülasyonu için zengin bir ekosistem sunan Pandas kütüphanesi ve DuckDB gibi bir veritabanı sisteminin yardımıyla SQL.\n",
    "\n",
    "```python\n",
    "# Python icinde sql gonderme\n",
    "import duckdb\n",
    "con = duckdb.connect('data')\n",
    "con.query(\"\"\"\n",
    "  select State, Measure, sum(Value) as \"Number of Passengers\" from data\n",
    "         where Date >= '2022-01-01' \n",
    "               and Date <= '2022-12-31'\n",
    "         group by State, Measure\n",
    "         order by \"Number of Passengers\" desc;\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# Ayni calisma alanina yukledikten sonra pandas ile yapma\n",
    "import pandas\n",
    "data=pd.read_csv(\"data\")\n",
    "data.query(\"Date>='2022-01-01' and Date<='2022-12-31'\")[['Value','State','Measure']].groupby(['State','Measure']).sum().sort_values(by='Value', ascending=False)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "1. **Birleştirme (Merging)**: Bu işlem, iki veya daha fazla farklı veri kaynağının birleştirilerek tutarlı ve birleşik bir veri kümesine dönüştürülmesini içerir. Birleştirme sayesinde, farklı kaynaklardan gelen bilgiler bir araya getirilir ve temel verinin daha kapsamlı bir şekilde analiz edilmesine ve anlaşılmasına olanak tanır. Bu, genellikle concatenation, joining veya union gibi çeşitli teknikler kullanılarak gerçekleştirilebilir.\n",
    "\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "\n",
    "   # Load customer and purchase data\n",
    "   customers = pd.read_csv('customer_data.csv')\n",
    "   purchases = pd.read_csv('purchase_history.csv')\n",
    "\n",
    "   # Merge the data using a common key (e.g., Customer ID)\n",
    "   merged_data = pd.merge(customers, purchases, on='CustomerID')\n",
    "   ```\n",
    "   \n",
    "   ```sql\n",
    "   -- Merge the data using a common key (CustomerID)\n",
    "   SELECT *\n",
    "   FROM customers\n",
    "   INNER JOIN purchases ON customers.CustomerID = purchases.CustomerID;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. **Filtreleme (Filtering)**: Veri genellikle önceden belirlenmiş kriterlere dayanarak belirli öğeleri seçerek düzenlenmelidir. Filtreleme, belirli koşulları karşılayan ilgili veriyi izole etme mekanizması olarak hizmet eder. Bu süreç, bir veri kümesinden değerli içgörüler çıkarmak ve gürültüyü ve ilgisiz bilgileri ortadan kaldırmak için önemlidir.\n",
    "\n",
    "   ```python\n",
    "   # Filter purchases for the year 2022\n",
    "   filtered_data = merged_data[merged_data['Year'] == 2022]\n",
    "   ```\n",
    "\n",
    "   ```sql\n",
    "   -- Filter purchases for the year 2022\n",
    "   SELECT *\n",
    "   FROM merged_data\n",
    "   WHERE Year = 2022;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. **Gruplama (Grouping)**: Gruplama, veriyi paylaşılan özelliklere veya niteliklere göre alt kümeler veya alt koleksiyonlara düzenleme imkanı sağlar. Bu işlem, veriyi farklı hiyerarşik seviyelerde analiz etmek veya belirli kategoriler içinde eğilimleri gözlemlemek için özellikle faydalıdır. Veri desenleri ve ilişkilerinin yapılandırılmış bir şekilde incelenmesine olanak tanır.\n",
    "\n",
    "   ```python\n",
    "   # Group data by 'ProductCategory' and calculate total sales\n",
    "   grouped_data = filtered_data.groupby('ProductCategory')['SalesAmount'].sum()\n",
    "   ```\n",
    "\n",
    "   ```sql\n",
    "   -- Group data by ProductCategory and calculate total sales\n",
    "   SELECT ProductCategory, SUM(SalesAmount) AS TotalSales\n",
    "   FROM filtered_data\n",
    "   GROUP BY ProductCategory;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4. **Fonksiyonları Uygulama (Applying Functions)**: Bir veri koleksiyonuna fonksiyonların uygulanması, mevcut veriden yeni bilgiler çıkarmak, veriyi dönüştürmek veya manipüle etmek için kullanılan çok yönlü bir tekniktir. Fonksiyonlar özel olarak oluşturulmuş veya önceden tanımlanmış olabilir ve çeşitli veri işleme görevleri için hesaplama motoru olarak hizmet eder. Bu fonksiyonlar matematiksel operasyonlardan karmaşık veri dönüşümlerine kadar çeşitli işlemleri kapsayabilir.\n",
    "\n",
    "   ```python\n",
    "   # Define a custom function to calculate profit margin\n",
    "   def calculate_profit_margin(row):\n",
    "       return (row['Profit'] / row['Revenue']) * 100\n",
    "\n",
    "   # Apply the custom function to each row\n",
    "   grouped_data['ProfitMargin'] = grouped_data.apply(calculate_profit_margin, axis=1)\n",
    "   ```\n",
    "\n",
    "    ```sql\n",
    "   -- Apply the custom function to calculate profit margin\n",
    "   SELECT ProductCategory, SUM(Profit) AS TotalProfit, SUM(Revenue) AS TotalRevenue,\n",
    "          CalculateProfitMargin(SUM(Profit), SUM(Revenue)) AS ProfitMargin\n",
    "   FROM grouped_data\n",
    "   GROUP BY ProductCategory;\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Feature Engineering ?: Gizli Desenleri Ortaya Çıkarmak\n",
    "\n",
    "**Özellik Mühendisliği**, ham verilerden yeni özellikler oluşturma sürecini kapsayan bir şemsiye terimdir. Veri ön işlemede önemli bir adım olan bu süreç, bilgide hemen göze çarpmayan gizli kalıpları ve ilişkileri ortaya çıkarmaya yardımcı olur. \n",
    "\n",
    "Özellik mühendisliği, makine öğrenimi modellerinin performansını artırmak ve verilerdeki gizli kalıpları ortaya çıkarmak amacıyla yeni özellikler oluşturma veya mevcut özellikleri dönüştürme sürecidir. Bu, alan bilgisi, matematiksel dönüşümler ve mevcut özelliklerin kombinasyonları dahil olmak üzere çeşitli teknikler kullanılarak gerçekleştirilebilir. Etkili bir şekilde yapıldığında, özellik mühendisliği, veri analizinden elde edilen içgörülerin kalitesini önemli ölçüde artırabilir ve algoritmaların verilerdeki karmaşık ilişkileri öğrenmesini kolaylaştırabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Feature Improvement \n",
    "\n",
    "Yapılandırılmış veri setlerinde genellikle mevcut sayısal özellikleri iyileştirmek için kullanılan \n",
    "\n",
    "- boş değerleri doldurma\n",
    "    * Nominal veya ordinal veri tipleri: mode\n",
    "    * Aralık ya da oran veri tipleri: ortalama, medyan vb\n",
    "- standartlaştırma\n",
    "- normalleştirme\n",
    "\n",
    "gibi teknikleri içerir.\n",
    "\n",
    "<img src=\"../images/feature-improvement.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Feature Construction\n",
    "\n",
    "Mevcut verilere, başka özelliklere dönüştürerek ya da başka kaynaklardan yeni özellikler eklenerek genişletilmesidir. Buna örnek olarak, kategorik verilere yapılan one-hot-encoding tekniği verilebilir. Tam tersi, yani sayısal verileri ayrıklaştırma ile de gruplara dönüştürülebilir. Diger taraftan, alan bilgisi kullanilarak  mevcut ozelliklerden uzerinde uygulanan teknikler (feature1/feature2) ve uygulanan matematiksel donusumler bu baslik altina girebilir.\n",
    "<img src=\"../images/feature-construction.png\" width=500 > <img src=\"../images/feature-construction-1.png\" width=500/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Feature Selection\n",
    "\n",
    "Makine öğrenimi işleri, verinin tüm özelliklerden eşit şekilde faydalanamayabilir. Özellik seçimi, var olan bir özellik kümesinden en uygun olanları seçme sürecini ifade eder. Bu süreç, modelin öğrenmesi gereken toplam özellik sayısını azaltmayı ve özelliklerin birbirine bağımlı olma olasılığını azaltmayı hedefler. Eğer bağımlı özelliklerle karşılaşılırsa, modelimizde karışıklıklara neden olabilecek özelliklerle karşılaşma riski ortaya çıkar ve bu genellikle genel performansta kötü sonuçlara yol açabilir. Bu kısmı detaylı bir şekilde inceleceyeğiz.\n",
    "\n",
    "<img src=\"../images/feature-selection.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Feature Extraction\n",
    "\n",
    "**Boyut Azaltma/Projeksiyonlar**: Bazen sahip olduğumuz veriler, hangi özelliğin önemli olduğu net olmadığı için deskriptif istatistikleri kullanılamaz hale getiren çok fazla özellik içerebilir. Ayrıca, çok sayıda özellik, verilerin görselleştirilmesini imkansız hale getirir. Bu gibi durumlarda, Temel Bileşen Analizi (Principal Component Analysis-PCA) ve Doğrusal Ayırıcı Analizi (Linear Discriminant Analysis-LDA) gibi farklı projeksiyon seçeneklerine bakarak özellik sayısını azaltabiliriz. \n",
    " \n",
    "Boyut azaltma, önemli bilgileri korurken bir veri setindeki özellik sayısını azaltmayı amaçlar. Bu, yüksek boyutlu verilerle ilişkili sorunları (örneğin artan hesaplama karmaşıklığı veya boyutun büyük olması nedeniyle model performansın azalması gibi) halletmeye yardımcı olur. PCA, gözetimsiz boyut azaltma için yaygın olarak kullanılırken, LDA özellikle sınıflandırma görevleri için faydalı olan gözetimli bir tekniktir.\n",
    "\n",
    "<img src=\"../images/feature-extraction.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Feature Learning\n",
    "\n",
    "Feature learning, bazen representation learning olarak da adlandırılır ve feature extraction ile benzerdir çünkü ham, yapılandırılmamış veriden, örneğin metin, resimler ve videolardan otomatik olarak bir özellik kümesi oluşturmaya çalışır. Ancak, Feature learning, orijinal temel verinin şekli hakkında hiçbir varsayım yapmayan (nonparametrik) bir derin öğrenme modeli uygulanarak gerçekleştirilir ve bu sayede orijinal verinin gizli bir temsilini otomatik olarak keşfetmeyi amaçlar. Örneğin;\n",
    "\n",
    "    - Generative Adversarial Networks\n",
    "    - Autoencoders\n",
    "    - Restricted Boltzmann Machines\n",
    "\n",
    "Diğer taraftan, düzenli satırlara ve sütunlara organize edilmiş olan yapılandırılmış verilerin aksine, yapısal olmayan verilerin makine tarafından okunabilir bir formata dönüştürülmesi için özel yöntemler gerekir. Örneğin, görüntü dosyaları piksel değerleri dizileri olarak temsil edilebilir ve metin verileri, Bag-of-Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF) veya Word Embeddings gibi teknikler kullanılarak kodlanabilir. Görüntü, metin ve ses gibi yapısal olmayan verilerin kodlamasını başlı başlına birer ders içeriği olarak düşünebilirsiniz. \n",
    "<img src=\"../images/feature-learning.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
